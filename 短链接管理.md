# 功能分析
  短链接跳转原理      核心功能：访问短链接，然后302跳转，重定向到原始链接。          分为301永久性和302临时性   前者是访问一次后，就会记录这个跳转信息，之后的访问跳转都不会去访问后端服务了，我们也就拿不到对应的用户的行为信息，所以我们要使用302.访问一次就去后端拿一次目标地址      
  创建短链接                输入原始地址，默认根据原始链接给出短链接标题也是网站的介绍，然后设置分组，设置有效期可以为永久或者自定义，然后会通过一个默认的域名带上我们生成的短链接，通过访问这个完整短链接就能跳到原始链接，同时附带监控，也有排序的功能，虽然看起来很简单，但是底层会有很多的复杂的情况要 
  考虑，详细看短链接管理v2，这里面监控和采集相关信息是很重要的，对用户来说不可见的。这里通过访问redis获取目标地址拿到后然后跳转。  
  新增短链接  
  修改短链接  
  短链接删除至回收站  
  Host添加域名映射  
  分页查询短链接集合  
  编辑短链接   

# 短链接创建
会有一个默认分组，我们保证的短链接唯一指的是完整的短链接唯一，也就是不同域名下的生成的随机短链接uri可能相同，但组合在一起就是唯一的  
短链接组成：https://  协议  baidu.com 域名 / 分隔符  adbsaf8 短链接uri    可以设置为6位， 这样能生成有62^6 会有500多亿   长链接通过hash函数生成一个10进制，在把它转化成62进制， 返回一个6位数值   
至于为什么不放在admin里面去实现，1：单一职责原则，一个服务就对应一种业务就好，admin就负责用户管理，短链接的业务与用户管理可以分离2：短链接创建 访问 跳转 监控会有很高的qps(访问量)，admin的访问量相对来说会很低，如果放到admin里面，admin可能会承受不住，这也就是我们前面设计注册用户功能时候，防止不了大量 不同的用户名去注册的场景，因为他本来的访问量就不高，如果真有也就加一层sentinal限流就好。3：更易维护和解耦，project可以单独做压力测试4：nacos做服务发现和Feign解耦，admin不直接操作数据库或redis，而是调用api到project里面执行.  

还是老样子 先创建ShortLinkDO ShortLinkMapper数据库操作层，即持久层   ShortLinkService ShortLinkServiceImpl 业务实现层   ShortLinkApplication 应用程序主入口。ShortLinkController  控制层  可以将规约包做一个抽象出来直接用   


3个问题：短链接不可重复，数据库唯一，短链接的防缓存穿透    mysql utf8mb4字符编码集忽略大小写的   可以改成utf8_bin   
短链接不可重复： 先是短链接请求传过来的DTO也就是ReqDTO包含了域名 原始链接 分组标识 创建类型 有效期类型 有效期 描述 传过来后，我们需要获取它对应的原始链接，然后利用这个原始链接生成对应的短链接，使用哈希取模的算法，     
HashUtil.hashToBase62(oriurl)，但是这里会有问题，就是可能获取到的短链接会重复，因此创建一个自循环，获取新的短链接直到不重复为止，这种情况在我们已经有了很多的短链接的存量之后，再去hash取模就可能出现碰撞，所以这时候设置最大自定义生成次数为10     
超过这个次数，就手动抛出异常短链接频繁生成稍后重试。这只是解决了不可重复问题的一半，创建短链接肯定是个高并发量的接口，会有很多的请求调用这个接口，那么如果这时候都要去查数据库的话会给数据库很大压力，我们会想到用分布式锁，但是这样会丧失很多性能，所以我们还是让它去查布隆过滤器，再创建一个短链接的专   属的布隆过滤器，布隆过滤器去查，如果完整短链接存在(因为我们允许不同域名下的短链接URI可以重复，因此存入布隆过滤器的是完整的短链接)那么一定会查到，然而如果完整短链接不存在，则可能会误判为存在(Hash碰撞，可能有别的完整短链接所占的位与要查的重复导致误判为存在)然后循环增加当前毫秒数偏移量再次生成(  
压测sentinal的时候发现会生成相同的短链接，后面 已经重构为UUID，因为如果在同一毫秒内大量请求打过来它们还是算作一样的请求)，我们之 前已经设置了完整短链接是唯一索引不可重复算作一个兜底。所以插入这个操作用try catch包起来，catch抛异常log.warn(),info()是正常运行的日志，若是写成info则会淹没在日志里无法   追踪，所以需要写成warn,代表室可控的，参数的异  常 ，情节轻微，若是error,则是重大异常，可能是数据丢失，事务回滚，系统异常，需要报警。考 虑到布隆过滤器的滞后性，也就是在并发场景下，两个相同的请求，也就是生成了同一个短链接去插入到数据库中时，就会触发唯一索引，这时候再次判断一次布隆过滤器是否存在  
，因为请求可能一前一后，一个已经插入到数据库里了并且也插入到布隆过滤器里面了，另一个触发了唯一索引，再去RBL判断一下如果存在，可以让其再生成一 个新的即可，若是不存在，则继续后续逻辑。@Builder 链式编程会优雅很多。  
这里有个算是业务的特殊的点所在，如果布隆过滤器误判即将不存在判为不存在，那么我们认为你要创建的这个完整短链接是存在的，从而再生成一个新的uri，这样那个有什么问题呢？ 没有什么问题，不能用这个完整短链接那就再创建一个嘛。无伤大雅，又不是说这个创建短链接的可能量很少，它是很大的，是可以支持这种情况的      这里加上@Transactional注解，两个操作数据库如果有一个失败都要回滚。  
#  优化点
🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎  写到这里的时候，如果确定在布隆过滤器存在 则会接着循环创建，但是生成的仍然是一样的，这样只能触发一种逻辑就是一条已经存在的短链接重复生成超过循环次数抛出短链接频繁生成。 这样不合理可以优化。 如果重复 将其加个随机偏移量 生成再进过   hashmod获取新的短链接。而且有一种情况实际上算是业务但也算是一个能被攻击的点，就是他能够用一个原始链接一直去生成短链接，因为我们的循环生成短链接判重之后加的偏移量是当前毫秒数，业务上虽然是支持的，也就是一个原始链接可以由多条url指向。如果别人一直去对一个原始链接创建短链接我们的应对方法是什么呢   

#  优化点
🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎🍎     
一个原始链接可以由多条url指向。如果别人一直去对一个原始链接创建短链接我们的应对方法是什么呢     
1：接口级 限流  思想 防止 同一个用户/ip短时间内多次调用创建接口  网关层 Redis + lua 或者Sentinal实现  nginx层： 使用limit_req_zone实现    应用层：代码内   
2：业务级：同链接去重或者限次   逻辑层面保护：同一用户在单位时间内 对同一个原始链接只能创建一次，或者最多创建N个短链   
3: 系统级：验证码/风控限制    针对大规模攻击例如机器人调用接口 可以在前端或者接口处加入验证码 黑名单   
通过压测的过程中会发现出现短链接重复，也就是UUID的失败率几乎为0  原始链接拼接时间戳失败率25%左右  
如果有人大量的请求在很短时间创建短链接，我们使用当前毫秒数的话可能会生成重复的短链接都去访问也会造成数据库的压力，所以我们使用UUID替代当前时间戳来降低短链接的重复的几率。  

# 分页查询短链接
请求参数继承Page是要传过来页数，第几页，每页多少数，好让我们返回，同样的响应参数也需要由IPage包裹起来，因为相应的参数他也得知道页数，每页数量。同时要配置mybatis-plus的mysql分页拦截器DataBaseConfiguration，  
MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor() interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); 给Mybatis-plus拦截器添加一个分页功能的内部拦截器，PaginationInnerInterceptor  
专门负责分页逻辑，自动帮你拼接LIMIT,计算总数等，DBType指定数据库类型，因为不同数据库分页与法不同。最终返回一个配置好的Mybati-Plus拦截器，Spring会把它注册到Mybats-plus的执行流程中去

# 短链接分组以及默认分组
用户都分表了，而且一个用户不止一个短链接分组，因此短链接分组也要分表。而且也要比用户分表数要多,返回的DTO还要返回当前分组下有多少短链接的数量，这里就要远程调用的服务了，在短链接服务里面加上一个  
ShortLinkGroupCountQuery查询分组和分组对应的数量，相当于是一个map<gid,count>,对应的sql语句 select gid, count(*) from t_link_4 where enable_status = 0 add gid in ('15') group by gid,可以选择写sql语句或者mybatis-plus实现,使用mybatis-plus要拼写sql语句  
的话不使用lambdaquery 直接使用query,查出来了然后admin远程在调用。 这个东西等于说是查询分组的时候连带着要返回分组内的数量，在groupList方法里面去远程调用Result<List<ShortLinkGroupCountQueryRespDTO>> listResult = shortLinkActualRemoteService  
                .listGroupShortLinkCount(groupDOList.stream().map(GroupDO::getGid).toList());获取到每个分组和对应的数量，java Stream的写法，从groupDOList中取出每个对象的gid字段，然后把它们组成一个新的List<String>作为远程调用的参数，    Result<List<ShortLinkGroupCountQueryRespDTO>>   listGroupShortLinkCount(@RequestParam("requestParam") List<String> requestParam);stream() 是 Java 8 提供的强大集合操作工具，让你用类似 SQL 的方式对数据做筛选、映射、排序、聚合等操作，语法简洁、可读性强、可链式调用。  

# 修改短链接
域名是可以修改的，涉及到一个场景，是否修改gid，若修改gid，要先删除原有记录，然后再插入新的记录，若不修改gid，只需在原有记录上进行修改即可。  修改的时候要传入两个gid，一个是原始gid，一个是修改后的gid，若是gid没有变更，很好说，原始记录直接进行修改即可，若是gid变更，则分为两种情况  
1：修改后的gid仍然路由到同一张link表里面，这时候就会触发唯一索引fullshorturl，我们会很自然想到唯一索引加上一个del_flag，这样意思是我们就只能修改一次了，即修改了一次gid路由到原表，原来记录删除，del_flag置为1，新增的del_flag置为0，那么如果我们之后还要在进行修改呢？假设这时候修改后的gid仍然  
路由到原表，那么这时候该如何插入前面两个记录的del_flag置为1吗？ 这样又触发唯一索引了，因此我们可以设置一个唯一索引 fullshorturl和del_time，每次修改如果修改了gid，删除原有的记录，deltime设置为当前毫秒数，即不会触发唯一索引。或者是另一种场景：我们想要使用某种定制的短链接,例如http://taobao.com/666aaa  
这种怎么办，意思这个短链接如果在某次活动的时候我们做淘宝活动分组gid假设为5，另一次活动我们仍然想使用这个但是分组变更了gid变为10了但是仍然路由到同一张表里面，使得频繁的修改，这样只有del_flag和fullshorturl所组成的唯一索引是不够用的所以组合要使用del_time实现了多次修改，同时也实现了不同gid对于同一个  fullshorurl的复用，而不是删掉了就不能再被别的分组所使用了。
2：修改后的gid不在同一张link表里，原表逻辑软删除，新表新增即可
同时，监控表以及其他的一些表里面也涉及到gid，如果gid更改，则其他的许多表也同样需要更改，
因此这时候有个问题，如果短链接正在修改分组，这时有用户正在访问短链接，统计监控相关的分组还是之前的数据，是否涉及到无法正确统计监控数据的问题呢？
引入分布式锁吗？  比如说在修改短链接之前引入一个分布式的独占锁，访问短链接的时候也引入一个独占锁，两者互不干扰，即修改的时候统计是拿不到锁的，统计的时候也是修改不了的。物理上互斥，不能同时获取锁，逻辑上互不干扰，统计的时候不会受到修改的影响，同样统计的时候不会受到修改的影响，而且为什么使用    
分布式锁，而不是用synchronized因为短链接访问可能是不同的机器上或服务器上，普通的synchronized只能在单个JVM上生效，这样的话若是 修改的业务下可以使用，也就是在同一时间同一条短链接只允许一个请求去修改，别的请求要等待锁，但是如果用到统计短链接上，那么同一条短链接在同一时间只允许一个用户去访问吗？  
读写锁：读写锁是一种用于管理对共享资源的访问的同步机制，允许多个线程同时读取共享资源，但在写入时独占访问，以确保数据的一致性和完整性。

这肯定是不现实的， 所以自然想到使用读写锁， 允许并发访问读取，但是写入则是串行，写入操作时，别的获取不到写锁或者读锁。若是在修改，获取不到读锁，手动抛出异常短链接正在被修改，请稍后访问。  
  
同样又引入了一个新的问题也就是在修改的时候，如果修改时间会久一点，那么这段时间就不允许访问了吗？ 如果访问时返回失败，那么统计数据该怎么办？  因此引入延迟队列， 1：基于内存的jdk自带的延迟队列，如果消息队列里堆积了很多消息，应用宕机了，消息也没了，这种因此不推荐 2：可以使用Redis基于Redisson的   
延迟队列，最好的情况我们使用RocketMQ kafka这种基于MQ的延迟队列，也就是把统计这个消息发给延迟队列，5s之后在进行统计，这时候肯定是变更好了，如果没有修改好，再扔到延迟队列里面周而复始。这里我们先是使用的Redis的基于Redisson的延迟队列，   
# 同样类似应对幂等所使用的消息id作为key
使用UUID作为消息ID，来保证记录监控统计延迟队列这里的消息幂等问题。

# 修改短链接的缓存
如果修改了短链接的有效期类型为自定义，将跳转缓存删掉，即缓存里面找不到的话，会去数据库里去找，如果数据库里找到是过期的就代表已经失效。就会写入一个is null的缓存。因此 这时候还要在判断，如果修改了之后是没有过期，要把



使用Object.equals(a,b) 安全地比较两个对象内容是否相同，避免空指针异常，如果只是使用a.equals(b)则需要判空，而前者则不需要，它的底层是
```
public static boolean equals(Object a, Object b) {
    return (a == b) || (a != null && a.equals(b));
}
```

# 短链接跳转
用户访问浏览器 输入短链接 访问nginx，代理到中台服务，获取短网址对应的原始网址，然后302重定向到原始网址。跳转业务，先判断是否存在于布隆过滤器，我们是通过gid进行分表的，此时用户传给我们的只有一个短链接，是没有gid的，因此引出一个路由表，t_link_goto，是以完整短链接进行分片的，找到gid，然后在通过  
gid找到原始网址。创建表了，就要在持久层里面创建对应的ShortLinkGotoDO以及对应的操作数据库的Mapper.同时我们创建一个短链接的同时要把它添加到对应的路由表里面，路由表包括id gid fullShortUrl.如果想要跳转的时候不加端口也就是默认的是80端口，这是需要nginx给我们代理实现的，也就是访问短网址，然后nginx会  
代理到对应的原始网址。

存在缓存击穿和缓存穿透问题
缓存击穿加上一个分布式锁，以及一个双重判定 也就是获取到锁的第一个请求重构缓存后，后续的请求获取到锁后都能够直接从缓存中获取了
缓存击穿：  
就是跳转的时候 如果某个短链接跳转前缀key失效了，这时候有大量的请求去访问，缓存key失效就会涌入到数据库，所以使用分布式锁。但是如果有秒杀的情况，也就是如果500w个请求同时访问，这时候只有一个请求成功，其他的全都要获取锁，或者失败或者等待(看具体实现)，就会很不友好，所以这里可以使用逻辑过期+真实过期时间  来 保证热点key不会过期，也就是逻辑过期时间后有请求访问我们就异步重构缓存，别的请求仍然访问旧值。这样到真的过期时间之前都应该会刷新缓存的。这样会降低key真正过期概率，但是针对缓存穿透没有作用，要彻底解决缓存击穿:  1 永不过期+异步刷新  2互斥锁 +限流 3多级缓存  redis+本地缓存.  
缓存穿透：
使用空值缓存+布隆过滤器，可以自己试一下 误判的场景。
缓存预热：  
防止缓存雪崩或者缓存穿透，热点数据先放到缓存里面，也就是应用开始时创建好短链接时就进行缓存预热。同样跳转的时候也要进行预热操作。
```
stringRedisTemplate.opsForValue().set(
                String.format(GOTO_SHORT_LINK_KEY, fullShortUrl),
                requestParam.getOriginUrl(),
                LinkUtil.getLinkCacheValidTime(requestParam.getValidDate()), TimeUnit.MILLISECONDS
        );
``` 
如果进入到数据库中查询，也存在两种情况 1：查询到不存在，然后执行不存在的逻辑，返回404然后写入isnull 空key，  2：查询到存在，但是有效期是在当前时间之前也就是 已经过期了，同样执行不存在逻辑。  
设置跳转404页面 单独写一个notfoundController，   @Controller, @RestController       前者返回的是从视图里面去匹配，后者则是会将返回值以json形式

# 根据网站链接获取到网页标题
是通过发起一个HTTP请求调用后端，把原始链接传过去然后返回一个标题。   接收请求所以写一个UrlTitleController,这是跟业务相关的，project服务提供短链接相关业务：创建，修改，跳转，监控，根据URL获取标题，所以写一个独立的controller和service和impl，避免职责混乱。
# 根据网站连接获取网站图标
可以让前端给我们传一个图片，我们后台要进行处理，可以设置成异步的，因为如果恶意的请求传过来一个很大的图片，那样返回给前端一直加载就不好。要给后端处理可以避免一个CORS跨域的问题，后端请求不用通过浏览器，2可以在后端做统一的图片的处理，设置同一格式例如 24 *24 这种，后端抓取一次就缓存到本地，之后就可以  
直接使用缓存。
